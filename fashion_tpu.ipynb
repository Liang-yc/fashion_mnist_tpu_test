{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_tpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_ixPCF98FWp",
        "colab_type": "code",
        "outputId": "bf83d4d0-e538-4d14-f77d-6a31d04f32f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.13.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 112kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.16.5)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow-gpu==1.13.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 23.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.33.6)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow-gpu==1.13.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 61.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.1)\n",
            "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.8.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0rc3 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0rc3 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, mock, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2daUzBgn4AXE",
        "colab_type": "code",
        "outputId": "a61f7eb4-0165-422f-8cd2-9a731f7e44e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "!pip install funcy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/3a/fc8323f913e8a9c6f33f7203547f8a2171223da5ed965f2541dafb10aa09/funcy-1.13-py2.py3-none-any.whl\n",
            "Installing collected packages: funcy\n",
            "Successfully installed funcy-1.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQSnnOegikzn",
        "colab_type": "code",
        "outputId": "872d8514-dd6b-441f-c6d6-4341d718e8f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# from data_set                  import load_data\n",
        "from funcy                     import concat, identity, juxt, partial, rcompose, repeat, repeatedly, take\n",
        "from keras.callbacks           import LearningRateScheduler\n",
        "from keras.layers              import Activation, Add, BatchNormalization, Conv2D, Dense, GlobalAveragePooling2D, Input\n",
        "from keras.models              import Model, save_model\n",
        "from keras.optimizers          import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers        import l2\n",
        "from keras.utils               import plot_model\n",
        "from operator                  import getitem\n",
        "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from scipy import misc\n",
        "import numpy\n",
        "import numpy.random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "import os\n",
        "import distutils\n",
        "import tensorflow as tf\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "from keras.engine import Layer, InputSpec\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "import  tensorflow as tf\n",
        "# aaa=tf.keras.layers.Input((1,1,1))\n",
        "# if distutils.version.LooseVersion(tf.__version__) < '1.14':\n",
        "#     raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n",
        "\n",
        "\n",
        "\n",
        "class SwitchableNormalization(Layer):\n",
        "    \"\"\"Switchable normalization layer\n",
        "\n",
        "    # Arguments\n",
        "        axis: Integer, the axis that should be normalized\n",
        "            (typically the features axis).\n",
        "            For instance, after a `Conv2D` layer with\n",
        "            `data_format=\"channels_first\"`,\n",
        "            set `axis=1` in `BatchNormalization`.\n",
        "        momentum: Momentum for the moving mean and the moving variance.\n",
        "        epsilon: Small float added to variance to avoid dividing by zero.\n",
        "        center: If True, add offset of `beta` to normalized tensor.\n",
        "            If False, `beta` is ignored.\n",
        "        scale: If True, multiply by `gamma`.\n",
        "            If False, `gamma` is not used.\n",
        "            When the next layer is linear (also e.g. `nn.relu`),\n",
        "            this can be disabled since the scaling\n",
        "            will be done by the next layer.\n",
        "        mean_weight_initializer: Initializer for mean weight\n",
        "        variance_weight_initializer: Initializer for variance weight\n",
        "        beta_initializer: Initializer for the beta weight.\n",
        "        gamma_initializer: Initializer for the gamma weight.\n",
        "        beta_regularizer: Optional regularizer for the beta weight.\n",
        "        gamma_regularizer: Optional regularizer for the gamma weight.\n",
        "        beta_constraint: Optional constraint for the beta weight.\n",
        "        gamma_constraint: Optional constraint for the gamma weight.\n",
        "\n",
        "    # Input shape\n",
        "        Arbitrary. Use the keyword argument `input_shape`\n",
        "        (tuple of integers, does not include the samples axis)\n",
        "        when using this layer as the first layer in a model.\n",
        "\n",
        "    # Output shape\n",
        "        Same shape as input.\n",
        "\n",
        "    # References\n",
        "        - [Differentiable Learning-to-Normalize via Switchable Normalization](https://arxiv.org/abs/1806.10779)\n",
        "        - [SN by pytorch](https://github.com/switchablenorms/Switchable-Normalization/blob/master/models/switchable_norm.py)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 axis=-1,\n",
        "                 momentum=0.99,\n",
        "                 epsilon=1e-5,\n",
        "                 center=True,\n",
        "                 scale=True,\n",
        "                 mean_weight_initializer='ones',\n",
        "                 variance_weight_initializer='ones',\n",
        "                 beta_initializer='zeros',\n",
        "                 gamma_initializer='ones',\n",
        "                 moving_mean_initializer='zeros',\n",
        "                 moving_variance_initializer='ones',\n",
        "                 beta_regularizer=None,\n",
        "                 gamma_regularizer=None,\n",
        "                 beta_constraint=None,\n",
        "                 gamma_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(SwitchableNormalization, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.axis = axis\n",
        "        self.momentum = momentum\n",
        "        self.epsilon = epsilon\n",
        "        self.center = center\n",
        "        self.scale = scale\n",
        "        self.mean_weight_initializer = initializers.get(mean_weight_initializer)\n",
        "        self.variance_weight_initializer = initializers.get(variance_weight_initializer)\n",
        "        self.beta_initializer = initializers.get(beta_initializer)\n",
        "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
        "        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\n",
        "        self.moving_variance_initializer = initializers.get(moving_variance_initializer)\n",
        "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
        "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
        "        self.beta_constraint = constraints.get(beta_constraint)\n",
        "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        dim = input_shape[self.axis]\n",
        "\n",
        "        if dim is None:\n",
        "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
        "                                                        'input tensor should have a defined dimension '\n",
        "                                                        'but the layer received an input with shape ' +\n",
        "                             str(input_shape) + '.')\n",
        "\n",
        "        self.input_spec = InputSpec(ndim=len(input_shape),\n",
        "                                    axes={self.axis: dim})\n",
        "\n",
        "        # add mean/variance weight\n",
        "        self.mean_weight = self.add_weight(shape=(3,),\n",
        "                                           name=\"mean_weight\",\n",
        "                                           initializer=self.mean_weight_initializer)\n",
        "        self.variance_weight = self.add_weight(shape=(3,),\n",
        "                                               name=\"variance_weight\",\n",
        "                                               initializer=self.variance_weight_initializer)\n",
        "\n",
        "        # add gamma/beta weight\n",
        "        shape = (dim,)\n",
        "        if self.scale:\n",
        "            self.gamma = self.add_weight(shape=shape,\n",
        "                                         name='gamma',\n",
        "                                         initializer=self.gamma_initializer,\n",
        "                                         regularizer=self.gamma_regularizer,\n",
        "                                         constraint=self.gamma_constraint)\n",
        "        else:\n",
        "            self.gamma = None\n",
        "        if self.center:\n",
        "            self.beta = self.add_weight(shape=shape,\n",
        "                                        name='beta',\n",
        "                                        initializer=self.beta_initializer,\n",
        "                                        regularizer=self.beta_regularizer,\n",
        "                                        constraint=self.beta_constraint)\n",
        "        else:\n",
        "            self.beta = None\n",
        "\n",
        "        self.moving_mean = self.add_weight(\n",
        "            shape=shape,\n",
        "            name=\"moving_mean\",\n",
        "            initializer=self.moving_mean_initializer,\n",
        "            trainable=False)\n",
        "        self.moving_variance = self.add_weight(\n",
        "            shape=shape,\n",
        "            name=\"moving_variance\",\n",
        "            initializer=self.moving_variance_initializer,\n",
        "            trainable=False)\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        input_shape = K.int_shape(inputs)\n",
        "        # Prepare broadcasting shape.\n",
        "        ndim = len(input_shape)\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
        "\n",
        "        # mean/variance of instance_normalization\n",
        "        reduction_axes_in = list(range(len(input_shape)))\n",
        "        del reduction_axes_in[self.axis]\n",
        "        del reduction_axes_in[0]\n",
        "        mean_in = K.mean(inputs, axis=reduction_axes_in, keepdims=True)\n",
        "        variance_in = K.var(inputs, axis=reduction_axes_in, keepdims=True)\n",
        "\n",
        "        # mean/variance of layer_normalization\n",
        "        reduction_axes_ln = list(range(len(input_shape)))\n",
        "        del reduction_axes_ln[0]\n",
        "        mean_ln = K.mean(inputs, axis=reduction_axes_ln, keepdims=True)\n",
        "        variance_ln = K.var(inputs, axis=reduction_axes_ln, keepdims=True)\n",
        "\n",
        "        # mean/variance of batch_normalization\n",
        "        reduction_axes_bn = list(range(len(input_shape)))\n",
        "        del reduction_axes_bn[self.axis]\n",
        "\n",
        "        def normed_training():\n",
        "            mean_bn = K.mean(inputs, axis=reduction_axes_bn, keepdims=True)\n",
        "            variance_bn = K.var(inputs, axis=reduction_axes_bn, keepdims=True)\n",
        "            mean = [mean_in, mean_ln, mean_bn]\n",
        "            variance = [variance_in, variance_ln, variance_bn]\n",
        "\n",
        "            # If the learning is either dynamic, or set to training:\n",
        "            self.add_update([K.moving_average_update(self.moving_mean,\n",
        "                                                     K.reshape(mean_bn, (input_shape[self.axis],)),\n",
        "                                                     self.momentum),\n",
        "                             K.moving_average_update(self.moving_variance,\n",
        "                                                     K.reshape(variance_bn, (input_shape[self.axis],)),\n",
        "                                                     self.momentum)],\n",
        "                            inputs)\n",
        "            return norm(mean, variance)\n",
        "\n",
        "        def normalize_inference():\n",
        "            mean_bn = self.moving_mean\n",
        "            variance_bn = self.moving_variance\n",
        "            mean = [mean_in, mean_ln, mean_bn]\n",
        "            variance = [variance_in, variance_ln, variance_bn]\n",
        "            return norm(mean, variance)\n",
        "\n",
        "        def norm(mean, variance):\n",
        "            mean_weight = K.softmax(self.mean_weight)\n",
        "            variance_weight = K.softmax(self.variance_weight)\n",
        "            norm_mean = mean_weight[0] * mean[0] + mean_weight[1] * mean[1] + mean_weight[2] * mean[2]\n",
        "            norm_variance = variance_weight[0] * variance[0] + variance_weight[1] * variance[1] + variance_weight[2] * \\\n",
        "                            variance[2]\n",
        "            normd = (inputs - norm_mean) / (K.sqrt(norm_variance + self.epsilon))\n",
        "            if self.scale:\n",
        "                broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
        "                normd = normd * broadcast_gamma\n",
        "            if self.center:\n",
        "                broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
        "                normd = normd + broadcast_beta\n",
        "            return normd\n",
        "\n",
        "        if training in {0, False}:\n",
        "            return normalize_inference\n",
        "\n",
        "        # Pick the normalized form corresponding to the training phase.\n",
        "        return K.in_train_phase(normed_training,\n",
        "                                normalize_inference,\n",
        "                                training=training)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'axis': self.axis,\n",
        "            'momentum': self.momentum,\n",
        "            'epsilon': self.epsilon,\n",
        "            'center': self.center,\n",
        "            'scale': self.scale,\n",
        "            'mean_weight_initializer': self.mean_weight_initializer,\n",
        "            'variance_weight_initializer': self.variance_weight_initializer,\n",
        "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
        "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
        "            'moving_mean_initializer': initializers.serialize(self.moving_mean_initializer),\n",
        "            'moving_variance_initializer': initializers.serialize(self.moving_variance_initializer),\n",
        "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
        "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
        "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
        "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
        "        }\n",
        "        base_config = super(SwitchableNormalization, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=1, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser\n",
        "\n",
        "\n",
        "def random_crop_image(image):\n",
        "      height, width = image.shape[:2]\n",
        "      random_array = numpy.random.random(size=4)\n",
        "      w = int((width*0.5)*(1+random_array[0]*0.5))\n",
        "      h = int((height*0.5)*(1+random_array[1]*0.5))\n",
        "      x = int(random_array[2]*(width-w))\n",
        "      y = int(random_array[3]*(height-h))\n",
        "\n",
        "      image_crop = image[y:h+y,x:w+x,0:3]\n",
        "      image_crop = misc.imresize(image_crop,image.shape)\n",
        "      return image_crop\n",
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import Input, Add, GlobalAveragePooling2D, Dropout\n",
        "from keras import regularizers\n",
        "\n",
        "weight_decay = 5e-4\n",
        "\n",
        "\n",
        "def conv3x3(input, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return tf.keras.layers.Conv2D(out_planes, kernel_size=3, strides=stride,\n",
        "                    padding='same', use_bias=False, kernel_initializer='he_normal',\n",
        "                    kernel_regularizer=regularizers.l2(weight_decay))(input)\n",
        "\n",
        "\n",
        "def conv1x1(input, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return tf.keras.layers.Conv2D(out_planes, kernel_size=1, strides=stride,\n",
        "                    padding='same', use_bias=False, kernel_initializer='he_normal',\n",
        "                    kernel_regularizer=regularizers.l2(weight_decay))(input)\n",
        "\n",
        "\n",
        "def BasicBlock(input, planes, dropout, stride=1):\n",
        "    inplanes = input.shape[3]\n",
        "\n",
        "    out = tf.keras.layers.BatchNormalization()(input)\n",
        "    # out = SwitchableNormalization()(input)\n",
        "    out = tf.keras.layers.Activation('elu')(out)\n",
        "    out = conv3x3(out, planes, stride)\n",
        "    out = tf.keras.layers.BatchNormalization()(out)\n",
        "    # out = SwitchableNormalization()(out)\n",
        "    out = tf.keras.layers.Activation('elu')(out)\n",
        "    out = tf.keras.layers.Dropout(dropout)(out)\n",
        "    out = conv3x3(out, planes)\n",
        "\n",
        "    if stride != 1 or inplanes != planes:\n",
        "        shortcut = conv1x1(input, planes, stride)\n",
        "    else:\n",
        "        shortcut = out\n",
        "\n",
        "    out = tf.keras.layers.Add()([out, shortcut])\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def WideResNet(depth=40, width=10,num_classes=10, dropout=0.3):\n",
        "    layer = (depth - 4) // 6\n",
        "\n",
        "    input = tf.keras.layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    x = conv3x3(input, 16)\n",
        "    for _ in range(layer):\n",
        "        x = BasicBlock(x, 16*width, dropout)\n",
        "    x = BasicBlock(x, 32*width, dropout, 2)\n",
        "    for _ in range(layer-1):\n",
        "        x = BasicBlock(x, 32*width, dropout)\n",
        "    x = BasicBlock(x, 64*width, dropout, 2)\n",
        "    for _ in range(layer-1):\n",
        "        x = BasicBlock(x, 64*width, dropout)\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    # x = SwitchableNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('elu')(x)\n",
        "    print(x.shape)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "#     x = tf.keras.layers.Conv2D(64, kernel_size=3, strides=2,\n",
        "#                     padding='valid', use_bias=False, kernel_initializer='he_normal',\n",
        "#                     kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
        "#     x = tf.keras.layers.Conv2D(64, kernel_size=3, strides=2,\n",
        "#                     padding='valid', use_bias=False, kernel_initializer='he_normal',\n",
        "#                     kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
        "#     x =tf.keras.layers.Flatten()(x)\n",
        "    # x=tf.reshape(x,shape=(-1,64))\n",
        "    output = tf.keras.layers.Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
        "\n",
        "    model = tf.keras.Model(input, output)\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnSoxQCUhQrU",
        "colab_type": "code",
        "outputId": "db3d9cf9-e825-4bf5-8f42-4401dcf06c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "from tensorflow.contrib.tpu.python.tpu import keras_support\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "print(np.min(x_train),np.max(x_train))\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "x_train = (np.float32(x_train)/255.-0.1307)/0.3081\n",
        "x_test = (np.float32(x_test)/255.-0.1307)/0.3081\n",
        "y_train = np_utils.to_categorical(y_train,10)\n",
        "y_test = np_utils.to_categorical(y_test,10)\n",
        "print(np.min(x_train),np.max(x_train))\n",
        "# resolver = tf.contrib.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "# tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "# strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "# with strategy.scope():\n",
        "#   model = create_model()\n",
        "tpu_model =WideResNet()\n",
        "tpu_model.compile(\n",
        "    optimizer=    tf.keras.optimizers.SGD(lr=0.01,\n",
        "             momentum=0.9,),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['categorical_accuracy'])\n",
        "\n",
        "tpu_grpc_url = \"grpc://\"+os.environ[\"COLAB_TPU_ADDR\"]\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "strategy = keras_support.TPUDistributionStrategy(tpu_cluster_resolver)\n",
        "\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(tpu_model, strategy=strategy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_data  = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=True,\n",
        "                                     featurewise_std_normalization=True,\n",
        "                                     # preprocessing_function=random_crop_image,\n",
        "                                     preprocessing_function=get_random_eraser(v_l=0, v_h=1),\n",
        "#                                      width_shift_range=0.125,\n",
        "#                                      height_shift_range=0.125,\n",
        "                                     horizontal_flip=True)\n",
        "validation_data = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "\n",
        "for data in (train_data, validation_data):\n",
        "    data.fit(x_train)  \n",
        "\n",
        "batch_size = 400\n",
        "epoch_size = 100000\n",
        "\n",
        "\n",
        "weights_file = \"./wrn_tpu.h5\"\n",
        "\n",
        "# if os.path.exists(weights_file):\n",
        "#     tpu_model.load_weights(weights_file)\n",
        "#     tpu_model = load_model(weights_file)\n",
        "#     print(\"Model loaded 1.\")\n",
        "#     tpu_model.save(weights_file)\n",
        "\n",
        "if os.path.exists(weights_file):\n",
        "#     tpu_model.load_weights(weights_file)\n",
        "    tpu_model = load_model(weights_file)\n",
        "    print(\"Model loaded.\")\n",
        "    tpu_model = tf.contrib.tpu.keras_to_tpu_model(tpu_model, strategy=strategy)\n",
        "    print('tpu schedule')\n",
        "\n",
        "# lr_reducer = tf.keras.callbacks.LearningRateScheduler(monitor='val_loss', factor=np.sqrt(0.1),\n",
        "#                                cooldown=0, patience=10, min_lr=1e-6)\n",
        "\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(weights_file, monitor=\"val_categorical_accuracy\", save_best_only=True,\n",
        "                                   save_weights_only=False, mode='auto')\n",
        "\n",
        "callbacks = [tf.keras.callbacks.LearningRateScheduler(partial(getitem, tuple(take(epoch_size, concat(repeat(0.1, 60), repeat(0.02, 60), repeat(0.004, 40), repeat(0.0008)))))), model_checkpoint]\n",
        "\n",
        "results = tpu_model.fit_generator(train_data.flow(x_train, y_train, batch_size=batch_size),\n",
        "                              steps_per_epoch=60000// batch_size,\n",
        "                              epochs=epoch_size,\n",
        "                              callbacks=callbacks,\n",
        "                              validation_data=validation_data.flow(x_test, y_test, batch_size=batch_size),\n",
        "                              validation_steps=10000 // batch_size)\n",
        "\n",
        "# results = model.fit(x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "#                               steps_per_epoch=int(60000// batch_size),\n",
        "#                               epochs=epoch_size,\n",
        "#                               callbacks=callbacks,\n",
        "#                               validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "#                               validation_steps=int(10000 // batch_size))\n",
        "\n",
        "# with open('./results/history.pickle', 'wb') as f:\n",
        "#     pickle.dump(results.history, f)\n",
        "\n",
        "model.save_weights('./wrn_tpu.h5', overwrite=True)\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "# model.save_weights('./fashion_mnist.h5', overwrite=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "0 255\n",
            "-0.42421296 2.8214867\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "(?, 7, 7, 640)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 16)   144         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 28, 28, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 28, 28, 16)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 160)  23040       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 28, 28, 160)  640         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 28, 28, 160)  0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 28, 28, 160)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 160)  230400      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 28, 160)  2560        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 28, 28, 160)  0           conv2d_2[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 28, 28, 160)  640         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 28, 28, 160)  0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 160)  230400      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 28, 28, 160)  640         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 28, 28, 160)  0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 28, 28, 160)  0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 160)  230400      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 28, 28, 160)  0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 28, 28, 160)  640         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 28, 28, 160)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 28, 160)  230400      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 28, 28, 160)  640         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 28, 28, 160)  0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 28, 28, 160)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 28, 160)  230400      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 28, 28, 160)  0           conv2d_7[0][0]                   \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 28, 28, 160)  640         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 28, 28, 160)  0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 160)  230400      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 28, 28, 160)  640         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 28, 28, 160)  0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 28, 28, 160)  0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 160)  230400      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 160)  0           conv2d_9[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 28, 28, 160)  640         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 28, 28, 160)  0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 160)  230400      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 28, 28, 160)  640         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 28, 28, 160)  0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 28, 28, 160)  0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 160)  230400      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 160)  0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 28, 28, 160)  640         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 160)  0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 28, 28, 160)  230400      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 28, 28, 160)  640         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 160)  0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 28, 28, 160)  0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 28, 28, 160)  230400      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 160)  0           conv2d_13[0][0]                  \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 28, 28, 160)  640         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 160)  0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 14, 14, 320)  460800      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 14, 14, 320)  1280        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 14, 14, 320)  0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 14, 14, 320)  921600      dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 14, 14, 320)  51200       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 14, 14, 320)  0           conv2d_15[0][0]                  \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 14, 14, 320)  1280        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 14, 14, 320)  921600      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 14, 14, 320)  1280        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 320)  0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 320)  921600      dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 14, 14, 320)  0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 14, 14, 320)  1280        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 14, 14, 320)  921600      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 14, 14, 320)  1280        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 320)  0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 14, 14, 320)  921600      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 320)  0           conv2d_20[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 14, 14, 320)  1280        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 14, 14, 320)  921600      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 14, 14, 320)  1280        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 320)  0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 14, 14, 320)  921600      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 320)  0           conv2d_22[0][0]                  \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 14, 14, 320)  1280        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 14, 14, 320)  921600      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 14, 14, 320)  1280        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 14, 14, 320)  0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 14, 14, 320)  921600      dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 320)  0           conv2d_24[0][0]                  \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 14, 14, 320)  1280        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 14, 14, 320)  921600      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 14, 14, 320)  1280        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 14, 14, 320)  0           activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 14, 14, 320)  921600      dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 320)  0           conv2d_26[0][0]                  \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 14, 14, 320)  1280        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 320)  0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 7, 7, 640)    1843200     activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 7, 7, 640)    2560        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 7, 7, 640)    0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 7, 7, 640)    3686400     dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 640)    204800      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 7, 7, 640)    0           conv2d_28[0][0]                  \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 640)    2560        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 640)    3686400     activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 7, 7, 640)    2560        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 7, 7, 640)    0           activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 640)    3686400     dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 7, 7, 640)    0           conv2d_31[0][0]                  \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 7, 7, 640)    2560        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 640)    3686400     activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 640)    2560        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 7, 7, 640)    0           activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 640)    3686400     dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 640)    0           conv2d_33[0][0]                  \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 640)    2560        add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 640)    3686400     activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 640)    2560        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 7, 7, 640)    0           activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 640)    3686400     dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 640)    0           conv2d_35[0][0]                  \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 640)    2560        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 640)    3686400     activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 640)    2560        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 7, 7, 640)    0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 640)    3686400     dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 640)    0           conv2d_37[0][0]                  \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 640)    2560        add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 640)    3686400     activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 640)    2560        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 7, 7, 640)    0           activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 640)    3686400     dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 640)    0           conv2d_39[0][0]                  \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 640)    2560        add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 640)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 640)          0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           6410        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 55,868,378\n",
            "Trainable params: 55,841,466\n",
            "Non-trainable params: 26,912\n",
            "__________________________________________________________________________________________________\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.51.157.194:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 11394735638504063955)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 13951558398528995328)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7825955456415872951)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10247490083318523702)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 15043036004500275864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15145865145925817830)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11438060349532881767)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 15881503339807971038)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 12241975895894026619)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14681330431258017369)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 16203991219310797706)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.009999999776482582, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.009999999776482582, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "Epoch 1/100000\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(50,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(50, 28, 28, 1), dtype=tf.float32, name='input_1_10'), TensorSpec(shape=(50, 10), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.10000000149011612, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.SGD object at 0x7f9d460da9b0> []\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 35.66215991973877 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.10000000149011612 {0.1}\n",
            "INFO:tensorflow:CPU -> TPU momentum: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: nesterov\n",
            " 76/150 [==============>...............] - ETA: 1:26 - loss: 15.4849 - categorical_accuracy: 0.4320"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-adf6b03d8283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                               validation_steps=10000 // batch_size)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# results = model.fit(x_train.astype(np.float32), y_train.astype(np.float32),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0mtpu_model_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfeed_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpu_model_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0mtpu_model_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutfeed_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m     ], infeed_dict)\n\u001b[0m\u001b[1;32m   1270\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfeed_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}